<!DOCTYPE html><!-- Last Published: Fri Nov 08 2024 01:48:40 GMT+0000 (Coordinated Universal Time) --><html data-wf-page="63507ef97fd4517167a4c788" data-wf-site="5fbc6a3c5640b420d5c9a25a"><head><meta charset="utf-8"/><title>reference-guide</title><meta content="reference-guide" property="og:title"/><meta content="reference-guide" property="twitter:title"/><meta content="width=device-width, initial-scale=1" name="viewport"/><link href="../css/webflow-style.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com" rel="preconnect"/><link href="https://fonts.gstatic.com" rel="preconnect" crossorigin="anonymous"/><script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.26/webfont.js" type="text/javascript"></script><script type="text/javascript">WebFont.load({  google: {    families: ["Montserrat:100,100italic,200,200italic,300,300italic,400,400italic,500,500italic,600,600italic,700,700italic,800,800italic,900,900italic","Questrial:regular","Roboto:300,regular,500","Roboto Condensed:300,regular"]  }});</script><script type="text/javascript">!function(o,c){var n=c.documentElement,t=" w-mod-";n.className+=t+"js",("ontouchstart"in o||o.DocumentTouch&&c instanceof DocumentTouch)&&(n.className+=t+"touch")}(window,document);</script><link href="../images/favicon.png" rel="shortcut icon" type="image/x-icon"/><link href="../images/app-icon.png" rel="apple-touch-icon"/></head><body class="body-2"><div data-collapse="medium" data-animation="default" data-duration="400" data-easing="ease" data-easing2="ease" data-doc-height="1" role="banner" class="navbar-3 w-nav"><div class="div_studynav_holder"><a href="/study/study" class="brand-link study_home_link w-nav-brand"><img src="../images/veil_logo_w_3.png" loading="lazy" width="97" alt="Virtual  Experience Interaction Lab" class="image-10"/></a><nav role="navigation" class="nav-menu-3 studydropmenu w-nav-menu"><a href="/study/personas" class="nav_link studydrop_tabs w-nav-link">Personas</a><a href="/study/summaries" class="nav_link studydrop_tabs w-nav-link">Summaries</a><a href="/study/evaluation" class="nav_link studydrop_tabs w-nav-link">Evaluation‍</a><a href="/study/interaction-pattern-library-copy" class="nav_link studydrop_tabs w-nav-link">White Papers</a><a href="/study/interaction-pattern-library" class="nav_link studydrop_tabs w-nav-link">Pattern Library</a><a href="https://sites.google.com/view/veilcompanion/" target="_blank" class="nav_link studydrop_tabs w-nav-link">Knowledge Base</a></nav><div class="menu-button-2 w-nav-button"><div class="icon w-icon-nav-menu"></div></div></div></div><div class="study_section01"><div class="block_tx_bt_div"><h2 id="headIN" class="heading-3 contact-r">Understanding Summaries Guide<br/></h2><h1 class="heading-12">Sense of Presence<br/></h1><p class="main-text">Presence is defined as the subjective experience of being in one place or environment, even when one is physically situated in another.  As applied to a virtual environment, presence refers to experiencing the simulated environment rather than the physical world. When experiencing presence, an individual may lose track of time or unconsciously forget the fact that they are in a virtual environment. Presence comprises four dimensions evaluated from 1 to 7, with higher scores associated with a higher experience of presence.<br/>‍<br/><strong>Agency and Control (Control Factors)<br/></strong>The more control, immediacy, and anticipation a person has over the task, environment, or interaction with the virtual environment (VE), the greater the experience of presence.<br/>‍<br/><strong>Realism</strong> <br/>FactorsSense of presence is defined in terms of scene continuity, consistency, and meaningfulness.<br/>‍<br/><strong>Sensory Factors<br/></strong>The consistency and coherence of the information received through all modalities highly influence the user’s immersion and the natural response to the virtual experience. <br/><br/><strong>Hardware Interference and Distraction <br/></strong>FactorsThe degree to which VR devices can sensorially isolate the user from the outside physical world influences the user&#x27;s ability to feel and respond to the simulation effectively and to generate a greater sense of immersion and presence.<br/></p></div><div class="block_tx_bt_div"><h1 class="heading-12">Embodiment<br/></h1><p class="main-text">Embodiment is the sense that something is a part of one’s body. The sense of one’s own body is argued to relate to the sense of agency of one’s own actions and the ownership of the body. Embodied avatars are defined to be avatars that are co-located with the user’s body and seen from a first-person perspective within an immersive virtual environment. This can also refer to the extension of one&#x27;s body, such as with tools or hands. Embodiment is composed of Body Ownership and Response to External Stimuli. Each item is scored from -3 (strongly disagree) to +3 (strongly agree), where higher scores are related to a higher sense of embodiment.<br/><br/><strong>Body Ownership<br/></strong>This refers to the sense that the virtual avatar is your own body. It may be a pair of hands or a full head-to-toe humanoid figure, animal or other. <br/>‍<br/><strong>Response to Stimuli<br/></strong>Virtual stimuli may, of course, affect the user’s virtual body. In virtual experiences, there aer often eventshat modify or threaten the body or body parts of the virtual avatar. If you are embodied in the virtual avatar, then you are likely to react as if your own body is threatened. <br/></p></div><div class="block_tx_bt_div"><h1 class="heading-12">Narrative<br/></h1><p class="main-text">Narrative refers to the story and emotions associated with the experience. Evaluators were asked to choose whether they experienced a narrative  element. If they did, they documented their feelings about this element. There are three sets of effects that can support the narrative: visual effects, sound effects, and physiological/psychological responses. <br/><br/><strong>Visual Effects<br/></strong>These effects depict the visual story elements related to the situation, such as the indicators of visual phenomena, emotional influencers in the scene, lighting for inducing a specific mood, or the objects without interactions.<br/><br/><strong>Sound Effects<br/></strong>These effects depict the audio story elements related to the situation, e.g., footsteps in the scene as phenomena, the cracking of fire to punctuate mood, or the acoustic landscape of a café.<br/><br/><strong>Haptic Effects<br/></strong>These effects depict the haptic story elements related to the situation, e.g., footsteps in the scene as phenomena, the cracking of fire to punctuate mood, or the acoustic landscape of a café.<br/></p></div><div class="block_tx_bt_div"><h1 class="heading-12">Physiological and Affective Responses<br/></h1><p class="main-text">Physiological and affective responses refer to the autonomic responses and subjective perceptions related to the use of the app.<br/><br/><strong>Interactions<br/>‍</strong><br/><strong>Selection method:</strong> Selection method refers to readying a virtual object for interaction without yet committing to taking that action. It is carried out by the input device controls and multiple selection options are not offered.<br/><strong><br/>Committing selections:</strong> Using the control devices, a number of actions can be carried out utilizing the grip button, direct touch, grip gesture, tracked hands, and buttons on the surface of the menu.	<br/><br/><strong>Manipulation:</strong> It is possible to modify the position, rotation, scale, and properties of selected objects by direct manipulation using the input device or tracked hands, using both mono- or synchronous bimanual interactions.<br/></p></div></div><div class="section_contribute footer"><div class="w-container"><div class="columns w-row"><div class="column-2 w-col w-col-6"><a href="http://www.veilab.org" class="brand-link w-nav-brand"><img src="../images/veil_logo_w_3.png" loading="lazy" width="59" alt=""/></a><div class="footer-logo">Copyright © 2022 Virtual Experience Interaction Lab</div></div><div class="social-footer-wrap w-col w-col-6"><a href="https://medium.com/@veilab" target="_blank" class="footer-social-link w-inline-block"><img src="../images/unnamed.png" width="29" alt="Twitter" class="footer-icon"/></a><a href="https://www.youtube.com/channel/UCzRF9pw1ZhxPDAFyO6kaWbQ" target="_blank" class="footer-social-link w-inline-block"><img src="../images/395164.png" width="29" alt="Twitter" class="footer-icon"/></a><a href="https://twitter.com/VEI_Lab" target="_blank" class="footer-social-link w-inline-block"><img src="../images/twitter-icon.svg" width="29" alt="Twitter" class="footer-icon"/></a><a href="https://www.linkedin.com/company/veilab" target="_blank" class="footer-social-link w-inline-block"><img src="../images/linktinlogo_w.png" srcset="../images/linktinlogo_w-p-500.png 500w, ../images/linktinlogo_w.png 512w" sizes="100vw" width="29" alt="LinkedIn" class="footer-icon"/></a><a href="mailto:hello@veilab.org" class="footer-social-link w-inline-block"><img src="../images/mail_icon.png" width="29" alt="LinkedIn" class="footer-icon"/></a></div></div></div></div><script src="../js/jquery.js" type="text/javascript"  ></script><script src="../js/webflow-script.js" type="text/javascript"></script></body></html>